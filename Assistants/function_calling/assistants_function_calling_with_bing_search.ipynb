{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistants function calling (Bing Search에서 검색)\n",
    "본 노트북에서는, [Bing Search APIs](https://www.microsoft.com/bing/apis/llm) and [function calling](https://learn.microsoft.com/azure/ai-services/openai/how-to/function-calling?tabs=python)와 [function calling](https://learn.microsoft.com/azure/ai-services/openai/how-to/function-calling?tabs=python)을 이용하여 Azure OpenAI 모델을 웹 데이터로부터 그라운드 하는 방법을 보여줍니다. 이 방법은 모델이 웹에서 검색하는 최신 데이터에 접근하는 좋은 방안입니다.\n",
    "\n",
    "[Bing Search 리소스](https://learn.microsoft.com/en-us/bing/search-apis/bing-web-search/create-bing-search-service-resource)와 Azure OpenAI 리소스가 사전에 생성되어 있어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소요 시간\n",
    "\n",
    "이 노트북을 실행하는데는 10분 정도 소요됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\\\n",
    "%pip install requests openai~=1.30.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터\n",
    "Azure OpenAI와 Bing Search의 리소스에서 아래의 설정 정보를 복사하여 업데이트 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from pathlib import Path\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "azure_endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\")\n",
    "aoai_api_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "deployment_name = os.getenv(\"AZURE_OAI_DEPLOYMENT\")\n",
    "api_version = \"2024-02-15-preview\"\n",
    "bing_search_subscription_key = os.getenv(\"BING_SEARCH_SUBSCRIPTION_KEY\")\n",
    "bing_search_url = os.getenv(\"BING_SEARCH_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bing Search API를 호출하기 위한 Function 정의\n",
    "Azure OpenAI와 Bing Search API를 사용하기 위한 좀 더 자세한 내용은 [Bing Search APIs, with your LLM](https://learn.microsoft.com/bing/search-apis/bing-web-search/use-display-requirements-llm)를 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Perform a bing search against the given query\n",
    "\n",
    "    @param query: Search query\n",
    "    @return: List of search results\n",
    "\n",
    "    \"\"\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": bing_search_subscription_key}\n",
    "    params = {\"q\": query, \"textDecorations\": False}\n",
    "    response = requests.get(bing_search_url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for result in search_results[\"webPages\"][\"value\"]:\n",
    "        output.append({\"title\": result[\"name\"], \"link\": result[\"url\"], \"snippet\": result[\"snippet\"]})\n",
    "\n",
    "    return json.dumps(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"Where will the 2032 olympics be held?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-end로 실행 해 보기\n",
    "다음 Cell들 에서는, Function Calling으로 Assistant를 실행하기 위한 몇가지 함수를 정의합니다. 이 모든 함수들은 마지막 셀에서 하나로 결합됩니다. 여기서 새로운 웹 검색 Assistant를 정의하고, 그 기능에 대한 지침을 제공하며, 질문을 할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_run_till_completion(\n",
    "    client: AzureOpenAI,\n",
    "    thread_id: str,\n",
    "    run_id: str,\n",
    "    available_functions: dict,\n",
    "    verbose: bool,\n",
    "    max_steps: int = 10,\n",
    "    wait: int = 3,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Poll a run until it is completed or failed or exceeds a certain number of iterations (MAX_STEPS)\n",
    "    with a preset wait in between polls\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param run_id: Run ID\n",
    "    @param assistant_id: Assistant ID\n",
    "    @param verbose: Print verbose output\n",
    "    @param max_steps: Maximum number of steps to poll\n",
    "    @param wait: Wait time in seconds between polls\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if (client is None and thread_id is None) or run_id is None:\n",
    "        print(\"Client, Thread ID and Run ID are required.\")\n",
    "        return\n",
    "    try:\n",
    "        cnt = 0\n",
    "        while cnt < max_steps:\n",
    "            run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
    "            if verbose:\n",
    "                print(\"Poll {}: {}\".format(cnt, run.status))\n",
    "            cnt += 1\n",
    "            if run.status == \"requires_action\":\n",
    "                tool_responses = []\n",
    "                if (\n",
    "                    run.required_action.type == \"submit_tool_outputs\"\n",
    "                    and run.required_action.submit_tool_outputs.tool_calls is not None\n",
    "                ):\n",
    "                    tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "\n",
    "                    for call in tool_calls:\n",
    "                        if call.type == \"function\":\n",
    "                            if call.function.name not in available_functions:\n",
    "                                raise Exception(\"Function requested by the model does not exist\")\n",
    "                            function_to_call = available_functions[call.function.name]\n",
    "                            tool_response = function_to_call(**json.loads(call.function.arguments))\n",
    "                            tool_responses.append({\"tool_call_id\": call.id, \"output\": tool_response})\n",
    "\n",
    "                run = client.beta.threads.runs.submit_tool_outputs(\n",
    "                    thread_id=thread_id, run_id=run.id, tool_outputs=tool_responses\n",
    "                )\n",
    "            if run.status == \"failed\":\n",
    "                print(\"Run failed.\")\n",
    "                break\n",
    "            if run.status == \"completed\":\n",
    "                break\n",
    "            time.sleep(wait)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message(\n",
    "    client: AzureOpenAI,\n",
    "    thread_id: str,\n",
    "    role: str = \"\",\n",
    "    content: str = \"\",\n",
    "    file_ids: Optional[list] = None,\n",
    "    metadata: Optional[dict] = None,\n",
    "    message_id: Optional[str] = None,\n",
    ") -> any:\n",
    "    \"\"\"\n",
    "    Create a message in a thread using the client.\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param role: Message role (user or assistant)\n",
    "    @param content: Message content\n",
    "    @param file_ids: Message file IDs\n",
    "    @param metadata: Message metadata\n",
    "    @param message_id: Message ID\n",
    "    @return: Message object\n",
    "\n",
    "    \"\"\"\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    if file_ids is None:\n",
    "        file_ids = []\n",
    "\n",
    "    if client is None:\n",
    "        print(\"Client parameter is required.\")\n",
    "        return None\n",
    "\n",
    "    if thread_id is None:\n",
    "        print(\"Thread ID is required.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        if message_id is not None:\n",
    "            return client.beta.threads.messages.retrieve(thread_id=thread_id, message_id=message_id)\n",
    "\n",
    "        if file_ids is not None and len(file_ids) > 0 and metadata is not None and len(metadata) > 0:\n",
    "            return client.beta.threads.messages.create(\n",
    "                thread_id=thread_id, role=role, content=content, file_ids=file_ids, metadata=metadata\n",
    "            )\n",
    "\n",
    "        if file_ids is not None and len(file_ids) > 0:\n",
    "            return client.beta.threads.messages.create(\n",
    "                thread_id=thread_id, role=role, content=content, file_ids=file_ids\n",
    "            )\n",
    "\n",
    "        if metadata is not None and len(metadata) > 0:\n",
    "            return client.beta.threads.messages.create(\n",
    "                thread_id=thread_id, role=role, content=content, metadata=metadata\n",
    "            )\n",
    "\n",
    "        return client.beta.threads.messages.create(thread_id=thread_id, role=role, content=content)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_print_messages(\n",
    "    client: AzureOpenAI, thread_id: str, verbose: bool, out_dir: Optional[str] = None\n",
    ") -> any:\n",
    "    \"\"\"\n",
    "    Retrieve a list of messages in a thread and print it out with the query and response\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param verbose: Print verbose output\n",
    "    @param out_dir: Output directory to save images\n",
    "    @return: Messages object\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if client is None and thread_id is None:\n",
    "        print(\"Client and Thread ID are required.\")\n",
    "        return None\n",
    "    try:\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "        display_role = {\"user\": \"User query\", \"assistant\": \"Assistant response\"}\n",
    "\n",
    "        prev_role = None\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n\\nCONVERSATION:\")\n",
    "        for md in reversed(messages.data):\n",
    "            if prev_role == \"assistant\" and md.role == \"user\" and verbose:\n",
    "                print(\"------ \\n\")\n",
    "\n",
    "            for mc in md.content:\n",
    "                # Check if valid text field is present in the mc object\n",
    "                if mc.type == \"text\":\n",
    "                    txt_val = mc.text.value\n",
    "                # Check if valid image field is present in the mc object\n",
    "                elif mc.type == \"image_file\":\n",
    "                    image_data = client.files.content(mc.image_file.file_id)\n",
    "                    if out_dir is not None:\n",
    "                        out_dir_path = Path(out_dir)\n",
    "                        if out_dir_path.exists():\n",
    "                            image_path = out_dir_path / (mc.image_file.file_id + \".png\")\n",
    "                            with image_path.open(\"wb\") as f:\n",
    "                                f.write(image_data.read())\n",
    "\n",
    "                if verbose:\n",
    "                    if prev_role == md.role:\n",
    "                        print(txt_val)\n",
    "                    else:\n",
    "                        print(\"{}:\\n{}\".format(display_role[md.role], txt_val))\n",
    "            prev_role = md.role\n",
    "        return messages\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"websearch-assistant\"\n",
    "instructions = \"\"\"You are an assistant designed to help people answer questions.\n",
    "\n",
    "You have access to query the web using Bing Search. You should call bing search whenever a question requires up to date information or could benefit from web data.\n",
    "\"\"\"\n",
    "\n",
    "message = {\"role\": \"user\", \"content\": \"How big is South Korea?\"}\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_bing\",\n",
    "            \"description\": \"Searches bing to get up-to-date information from the web.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "available_functions = {\"search_bing\": search}\n",
    "verbose_output = True\n",
    "\n",
    "client = AzureOpenAI(api_key=aoai_api_key, api_version=api_version, azure_endpoint=azure_endpoint)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=name, description=\"\", instructions=instructions, tools=tools, model=deployment_name\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "create_message(client, thread.id, message[\"role\"], message[\"content\"])\n",
    "run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id, instructions=instructions)\n",
    "poll_run_till_completion(\n",
    "    client=client, thread_id=thread.id, run_id=run.id, available_functions=available_functions, verbose=verbose_output\n",
    ")\n",
    "messages = retrieve_and_print_messages(client=client, thread_id=thread.id, verbose=verbose_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
